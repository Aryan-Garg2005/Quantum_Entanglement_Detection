{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X95c6KMjrVH"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def idx(iA, jB, n=3):\n",
        "    return iA * n + jB\n",
        "\n",
        "def normalize_adjacency(A):\n",
        "    norm = np.linalg.norm(A, 'fro')\n",
        "    if norm > 0:\n",
        "        A = A / norm\n",
        "    return A\n",
        "\n",
        "\n",
        "def random_weighted_graph_qutrit(p=0.5):\n",
        "    \"\"\"\n",
        "    Random weighted graph on 3x3 vertices with fixed tensor labeling\n",
        "    and Frobenius normalization ||A||_F = 1\n",
        "    \"\"\"\n",
        "    A = np.zeros((9, 9))\n",
        "    for iA in range(3):\n",
        "        for jB in range(3):\n",
        "            u = idx(iA, jB)\n",
        "            for kA in range(3):\n",
        "                for lB in range(3):\n",
        "                    v = idx(kA, lB)\n",
        "                    if u < v and np.random.rand() < p:\n",
        "                        w = np.random.rand()\n",
        "                        A[u, v] = w\n",
        "                        A[v, u] = w\n",
        "    return normalize_adjacency(A)\n",
        "def partial_transpose_adj(A, m=3, n=3):\n",
        "    AT = np.zeros_like(A)\n",
        "    for iA in range(m):\n",
        "        for jB in range(n):\n",
        "            u = idx(iA, jB)\n",
        "            for kA in range(m):\n",
        "                for lB in range(n):\n",
        "                    v = idx(kA, lB)\n",
        "                    AT[idx(iA, lB), idx(kA, jB)] = A[u, v]\n",
        "    return AT\n",
        "\n",
        "def alpha_positivity(A):\n",
        "    d = A.sum(axis=1)\n",
        "    delta = d.min()\n",
        "    lambda_min = np.linalg.eigvalsh(A)[0]\n",
        "\n",
        "    if lambda_min >= 0:\n",
        "        return 0.0\n",
        "    return lambda_min / (lambda_min - delta)\n",
        "\n",
        "def alpha_ppt_threshold(A, m=3, n=3):\n",
        "    d = A.sum(axis=1)\n",
        "    dG = d.sum()\n",
        "    sum_d2 = np.sum(d**2)\n",
        "\n",
        "    term = (dG**2) / (m*n - 1) - sum_d2\n",
        "    if term <= 0:\n",
        "        return 1.0\n",
        "\n",
        "    return 1.0 / (1.0 + np.sqrt(term / np.linalg.norm(A, 'fro')**2))\n",
        "\n",
        "def triangle_term(A_TB):\n",
        "    return np.trace(A_TB @ A_TB @ A_TB) / 6.0\n",
        "\n",
        "def violates_moment_inequality(A, alpha):\n",
        "    d = A.sum(axis=1)\n",
        "    dG = d.sum()\n",
        "    sum_d2 = np.sum(d**2)\n",
        "    sum_d3 = np.sum(d**3)\n",
        "\n",
        "    A_TB = partial_transpose_adj(A)\n",
        "\n",
        "    edge_sum = 0.0\n",
        "    for i in range(9):\n",
        "        for j in range(i+1, 9):\n",
        "            if A_TB[i, j] != 0:\n",
        "                edge_sum += (d[i] + d[j]) * (A_TB[i, j]**2)\n",
        "\n",
        "    tri = triangle_term(A_TB)\n",
        "    beta = (1 - alpha) / alpha\n",
        "\n",
        "    LHS = (sum_d2 + beta**2 * np.linalg.norm(A, 'fro')**2)**2\n",
        "    RHS = dG * (\n",
        "        sum_d3\n",
        "        + 3 * beta**2 * edge_sum\n",
        "        + 6 * beta**3 * tri\n",
        "    )\n",
        "\n",
        "    return LHS > RHS\n",
        "def density_matrix_from_graph(A, alpha):\n",
        "    d = A.sum(axis=1)\n",
        "    dG = d.sum()\n",
        "    if dG <= 0:\n",
        "        return None\n",
        "    D = np.diag(d)\n",
        "    return (alpha * D + (1 - alpha) * A) / (alpha * dG)"
      ],
      "metadata": {
        "id": "OW0zHVK_kHFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_state_from_graph(A, alpha):\n",
        "    alpha0 = alpha_positivity(A)\n",
        "    if alpha < alpha0:\n",
        "        return None  # unphysical\n",
        "\n",
        "    alpha_ppt = alpha_ppt_threshold(A)\n",
        "\n",
        "    if alpha < alpha_ppt:\n",
        "        return \"ENT\"  # NPT entangled\n",
        "\n",
        "    if violates_moment_inequality(A, alpha):\n",
        "        return \"BE\"   # PPT entangled (bound)\n",
        "    else:\n",
        "        return \"SEP\"  # separable (paper-certified)\n",
        "\n",
        "def stratified_alphas(alpha_low, alpha_high, k, eps_frac=0.1):\n",
        "    \"\"\"\n",
        "    Returns k alpha values stratified into:\n",
        "    - lower boundary\n",
        "    - middle\n",
        "    - upper boundary\n",
        "    \"\"\"\n",
        "    if alpha_high <= alpha_low:\n",
        "        return []\n",
        "\n",
        "    width = alpha_high - alpha_low\n",
        "    eps = eps_frac * width\n",
        "\n",
        "    alphas = []\n",
        "\n",
        "    # lower boundary\n",
        "    alphas.append(\n",
        "        np.random.uniform(alpha_low, alpha_low + eps)\n",
        "    )\n",
        "\n",
        "    # middle\n",
        "    if k > 2:\n",
        "        alphas.extend(\n",
        "            np.random.uniform(\n",
        "                alpha_low + eps,\n",
        "                alpha_high - eps,\n",
        "                k - 2\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # upper boundary\n",
        "    alphas.append(\n",
        "        np.random.uniform(alpha_high - eps, alpha_high)\n",
        "    )\n",
        "\n",
        "    return alphas"
      ],
      "metadata": {
        "id": "LnpaU_urkrcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gell_mann_matrices():\n",
        "    l = []\n",
        "    l.append(np.array([[0,1,0],[1,0,0],[0,0,0]]))\n",
        "    l.append(np.array([[0,-1j,0],[1j,0,0],[0,0,0]]))\n",
        "    l.append(np.array([[1,0,0],[0,-1,0],[0,0,0]]))\n",
        "    l.append(np.array([[0,0,1],[0,0,0],[1,0,0]]))\n",
        "    l.append(np.array([[0,0,-1j],[0,0,0],[1j,0,0]]))\n",
        "    l.append(np.array([[0,0,0],[0,0,1],[0,1,0]]))\n",
        "    l.append(np.array([[0,0,0],[0,0,-1j],[0,1j,0]]))\n",
        "    l.append((1/np.sqrt(3))*np.array([[1,0,0],[0,1,0],[0,0,-2]]))\n",
        "    return l\n",
        "\n",
        "I3 = np.eye(3)\n",
        "GM = [I3] + gell_mann_matrices()\n",
        "\n",
        "def gell_mann_features(rho):\n",
        "    feats = []\n",
        "    for i in range(9):\n",
        "        for j in range(9):\n",
        "            if i == 0 and j == 0:\n",
        "                continue  # skip I ⊗ I\n",
        "            op = np.kron(GM[i], GM[j])\n",
        "            feats.append(np.trace(rho @ op).real)\n",
        "    return np.array(feats)"
      ],
      "metadata": {
        "id": "v2p0Pt6-kzIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_unitary(n=3):\n",
        "    \"\"\"\n",
        "    Haar-random unitary from U(n)\n",
        "    \"\"\"\n",
        "    Z = (np.random.randn(n, n) + 1j * np.random.randn(n, n)) / np.sqrt(2)\n",
        "    Q, R = np.linalg.qr(Z)\n",
        "\n",
        "    # Fix phases\n",
        "    d = np.diag(R)\n",
        "    Q = Q * (d / np.abs(d))\n",
        "\n",
        "    return Q\n",
        "\n",
        "def apply_local_unitary(rho):\n",
        "    UA = random_unitary(3)\n",
        "    UB = random_unitary(3)\n",
        "    U = np.kron(UA, UB)\n",
        "    return U @ rho @ U.conj().T"
      ],
      "metadata": {
        "id": "73gPKJe8k2iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(\n",
        "    n,\n",
        "    p_min=0.1,\n",
        "    p_max=0.9,\n",
        "    k_ent=3,\n",
        "    k_sep=3,\n",
        "    k_lu=2,\n",
        "    eps_frac=0.1,\n",
        "    max_trials=10_000_000\n",
        "):\n",
        "    \"\"\"\n",
        "    Balanced dataset with:\n",
        "      - randomized p\n",
        "      - stratified alpha sampling\n",
        "      - multiple alpha per graph\n",
        "      - local unitary augmentation\n",
        "    \"\"\"\n",
        "\n",
        "    X, Y = [], []\n",
        "    n_ent = n_sep = 0\n",
        "    trials = 0\n",
        "\n",
        "    while (n_ent < n or n_sep < n) and trials < max_trials:\n",
        "        trials += 1\n",
        "\n",
        "        # ---- sample graph ----\n",
        "        p_sample = np.random.uniform(p_min, p_max)\n",
        "        A = random_weighted_graph_qutrit(p=p_sample)\n",
        "\n",
        "        if np.sum(A) == 0:\n",
        "            continue\n",
        "\n",
        "        alpha0 = alpha_positivity(A)\n",
        "        if alpha0 >= 1.0:\n",
        "            continue\n",
        "\n",
        "        alpha_ppt = alpha_ppt_threshold(A)\n",
        "\n",
        "        # ---------- ENTANGLED ----------\n",
        "        if n_ent < n and alpha0 < alpha_ppt:\n",
        "            alphas_ent = stratified_alphas(\n",
        "                alpha0, alpha_ppt, k_ent, eps_frac\n",
        "            )\n",
        "\n",
        "            for alpha in alphas_ent:\n",
        "                if n_ent >= n:\n",
        "                    break\n",
        "                if classify_state_from_graph(A, alpha) == \"ENT\":\n",
        "                    rho = density_matrix_from_graph(A, alpha)\n",
        "                    if rho is None:\n",
        "                        continue\n",
        "\n",
        "                    for _ in range(k_lu):\n",
        "                        rho_aug = apply_local_unitary(rho)\n",
        "                        X.append(gell_mann_features(rho_aug))\n",
        "                        Y.append(1)\n",
        "                        n_ent += 1\n",
        "                        if n_ent >= n:\n",
        "                            break\n",
        "\n",
        "        # ---------- SEPARABLE ----------\n",
        "        alpha_min = max(alpha0, alpha_ppt)\n",
        "        if n_sep < n and alpha_min < 1.0:\n",
        "            alphas_sep = stratified_alphas(\n",
        "                alpha_min, 1.0, k_sep, eps_frac\n",
        "            )\n",
        "\n",
        "            for alpha in alphas_sep:\n",
        "                if n_sep >= n:\n",
        "                    break\n",
        "                if classify_state_from_graph(A, alpha) == \"SEP\":\n",
        "                    rho = density_matrix_from_graph(A, alpha)\n",
        "                    if rho is None:\n",
        "                        continue\n",
        "\n",
        "                    for _ in range(k_lu):\n",
        "                        rho_aug = apply_local_unitary(rho)\n",
        "                        X.append(gell_mann_features(rho_aug))\n",
        "                        Y.append(0)\n",
        "                        n_sep += 1\n",
        "                        if n_sep >= n:\n",
        "                            break\n",
        "\n",
        "        if (n_ent + n_sep) % 2000 == 0 and (n_ent + n_sep) > 0:\n",
        "            print(\n",
        "                f\"ENT: {n_ent}/{n}, \"\n",
        "                f\"SEP: {n_sep}/{n}, \"\n",
        "                f\"graphs tried: {trials}\"\n",
        "            )\n",
        "\n",
        "    if n_ent < n or n_sep < n:\n",
        "        raise RuntimeError(\n",
        "            f\"Could not build balanced dataset. \"\n",
        "            f\"ENT={n_ent}, SEP={n_sep}, trials={trials}\"\n",
        "        )\n",
        "\n",
        "    return np.array(X), np.array(Y)"
      ],
      "metadata": {
        "id": "s3gmrJBkk6Kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n"
      ],
      "metadata": {
        "id": "YAXZkiV0lCSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = build_dataset(\n",
        "    n=50000,\n",
        "    p_min=0.1,\n",
        "    p_max=0.9,\n",
        "    k_ent=3,\n",
        "    k_sep=3,\n",
        "    k_lu=2,\n",
        "    eps_frac=0.1\n",
        ")\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.2, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape)\n",
        "print(\"Val:\", X_val.shape)\n",
        "print(\"Test:\", X_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXQxiEeJlUyi",
        "outputId": "556d38f3-b77a-4469-a78e-9fbbcdf41432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENT: 3876/50000, SEP: 2124/50000, graphs tried: 824\n",
            "ENT: 7782/50000, SEP: 4218/50000, graphs tried: 1664\n",
            "ENT: 11688/50000, SEP: 6312/50000, graphs tried: 2509\n",
            "ENT: 15612/50000, SEP: 8388/50000, graphs tried: 3345\n",
            "ENT: 23274/50000, SEP: 12726/50000, graphs tried: 5006\n",
            "ENT: 27156/50000, SEP: 14844/50000, graphs tried: 5834\n",
            "ENT: 30942/50000, SEP: 17058/50000, graphs tried: 6629\n",
            "ENT: 34782/50000, SEP: 19218/50000, graphs tried: 7449\n",
            "ENT: 38682/50000, SEP: 21318/50000, graphs tried: 8286\n",
            "ENT: 42618/50000, SEP: 23382/50000, graphs tried: 9110\n",
            "ENT: 46464/50000, SEP: 25536/50000, graphs tried: 9961\n",
            "ENT: 50000/50000, SEP: 30000/50000, graphs tried: 11672\n",
            "ENT: 50000/50000, SEP: 36000/50000, graphs tried: 14008\n",
            "ENT: 50000/50000, SEP: 36000/50000, graphs tried: 14010\n",
            "ENT: 50000/50000, SEP: 36000/50000, graphs tried: 14011\n",
            "ENT: 50000/50000, SEP: 42000/50000, graphs tried: 16434\n",
            "ENT: 50000/50000, SEP: 48000/50000, graphs tried: 18750\n",
            "ENT: 50000/50000, SEP: 50000/50000, graphs tried: 19531\n",
            "Train: (64000, 80)\n",
            "Val: (16000, 80)\n",
            "Test: (20000, 80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def focal_loss(gamma=2.0, alpha=0.5):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
        "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        return -alpha * tf.reduce_mean((1 - pt)**gamma * tf.math.log(pt))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "28XJbk9MoYUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled   = scaler.transform(X_val)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "def build_mlp(input_dim, seed):\n",
        "    tf.keras.utils.set_random_seed(seed)\n",
        "\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu',\n",
        "              kernel_regularizer=l2(5e-5),\n",
        "              input_shape=(input_dim,)),\n",
        "        Dropout(0.1),\n",
        "\n",
        "        Dense(64, activation='relu',\n",
        "              kernel_regularizer=l2(5e-5)),\n",
        "        Dropout(0.1),\n",
        "\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_single_mlp(X_train, y_train, X_val, y_val, seed):\n",
        "    model = build_mlp(X_train.shape[1], seed)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
        "        loss=focal_loss(gamma=2.0),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=200,\n",
        "        batch_size=128,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "N_ENSEMBLE = 5\n",
        "SEEDS = [10, 20, 30, 40, 50]\n",
        "\n",
        "models = []\n",
        "\n",
        "for i, seed in enumerate(SEEDS):\n",
        "    print(f\"Training model {i+1}/{N_ENSEMBLE} (seed={seed})\")\n",
        "    model = train_single_mlp(\n",
        "        X_train_scaled, y_train,\n",
        "        X_val_scaled, y_val,\n",
        "        seed\n",
        "    )\n",
        "    models.append(model)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unFqq4ydmOep",
        "outputId": "bec695b7-20dd-4df7-88cd-c84eab00f635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model 1/5 (seed=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5864 - loss: 0.0978 - val_accuracy: 0.8153 - val_loss: 0.0632\n",
            "Epoch 2/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7990 - loss: 0.0610 - val_accuracy: 0.8618 - val_loss: 0.0463\n",
            "Epoch 3/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8526 - loss: 0.0470 - val_accuracy: 0.8783 - val_loss: 0.0395\n",
            "Epoch 4/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8762 - loss: 0.0402 - val_accuracy: 0.8879 - val_loss: 0.0360\n",
            "Epoch 5/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8890 - loss: 0.0363 - val_accuracy: 0.8903 - val_loss: 0.0344\n",
            "Epoch 6/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8973 - loss: 0.0338 - val_accuracy: 0.8957 - val_loss: 0.0330\n",
            "Epoch 7/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9044 - loss: 0.0317 - val_accuracy: 0.8958 - val_loss: 0.0324\n",
            "Epoch 8/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9113 - loss: 0.0299 - val_accuracy: 0.8969 - val_loss: 0.0318\n",
            "Epoch 9/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9133 - loss: 0.0293 - val_accuracy: 0.8967 - val_loss: 0.0317\n",
            "Epoch 10/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9191 - loss: 0.0275 - val_accuracy: 0.8956 - val_loss: 0.0316\n",
            "Epoch 11/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9211 - loss: 0.0269 - val_accuracy: 0.8959 - val_loss: 0.0313\n",
            "Epoch 12/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9235 - loss: 0.0262 - val_accuracy: 0.8977 - val_loss: 0.0309\n",
            "Epoch 13/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9252 - loss: 0.0256 - val_accuracy: 0.8992 - val_loss: 0.0310\n",
            "Epoch 14/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9291 - loss: 0.0249 - val_accuracy: 0.8991 - val_loss: 0.0313\n",
            "Epoch 15/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9318 - loss: 0.0244 - val_accuracy: 0.8994 - val_loss: 0.0312\n",
            "Epoch 16/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9324 - loss: 0.0239 - val_accuracy: 0.8998 - val_loss: 0.0312\n",
            "Epoch 17/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9340 - loss: 0.0238 - val_accuracy: 0.8999 - val_loss: 0.0310\n",
            "Epoch 18/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9363 - loss: 0.0231 - val_accuracy: 0.9002 - val_loss: 0.0314\n",
            "Epoch 19/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9344 - loss: 0.0230 - val_accuracy: 0.8996 - val_loss: 0.0313\n",
            "Epoch 20/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9374 - loss: 0.0224 - val_accuracy: 0.9016 - val_loss: 0.0316\n",
            "Epoch 21/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9394 - loss: 0.0221 - val_accuracy: 0.9016 - val_loss: 0.0312\n",
            "Epoch 22/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9401 - loss: 0.0220 - val_accuracy: 0.9019 - val_loss: 0.0311\n",
            "Training model 2/5 (seed=20)\n",
            "Epoch 1/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5916 - loss: 0.0942 - val_accuracy: 0.8158 - val_loss: 0.0618\n",
            "Epoch 2/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7984 - loss: 0.0604 - val_accuracy: 0.8628 - val_loss: 0.0457\n",
            "Epoch 3/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8525 - loss: 0.0468 - val_accuracy: 0.8807 - val_loss: 0.0393\n",
            "Epoch 4/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8752 - loss: 0.0399 - val_accuracy: 0.8896 - val_loss: 0.0358\n",
            "Epoch 5/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8873 - loss: 0.0361 - val_accuracy: 0.8947 - val_loss: 0.0340\n",
            "Epoch 6/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8970 - loss: 0.0338 - val_accuracy: 0.8973 - val_loss: 0.0327\n",
            "Epoch 7/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9056 - loss: 0.0312 - val_accuracy: 0.8973 - val_loss: 0.0319\n",
            "Epoch 8/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9106 - loss: 0.0302 - val_accuracy: 0.8979 - val_loss: 0.0313\n",
            "Epoch 9/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9145 - loss: 0.0289 - val_accuracy: 0.9006 - val_loss: 0.0311\n",
            "Epoch 10/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9181 - loss: 0.0280 - val_accuracy: 0.9012 - val_loss: 0.0307\n",
            "Epoch 11/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9197 - loss: 0.0271 - val_accuracy: 0.8999 - val_loss: 0.0310\n",
            "Epoch 12/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9237 - loss: 0.0263 - val_accuracy: 0.9001 - val_loss: 0.0304\n",
            "Epoch 13/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9262 - loss: 0.0255 - val_accuracy: 0.9026 - val_loss: 0.0304\n",
            "Epoch 14/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9290 - loss: 0.0249 - val_accuracy: 0.9045 - val_loss: 0.0301\n",
            "Epoch 15/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9301 - loss: 0.0245 - val_accuracy: 0.9028 - val_loss: 0.0308\n",
            "Epoch 16/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9301 - loss: 0.0242 - val_accuracy: 0.9026 - val_loss: 0.0304\n",
            "Epoch 17/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9337 - loss: 0.0235 - val_accuracy: 0.9045 - val_loss: 0.0301\n",
            "Epoch 18/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9343 - loss: 0.0233 - val_accuracy: 0.9066 - val_loss: 0.0299\n",
            "Epoch 19/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9370 - loss: 0.0228 - val_accuracy: 0.9040 - val_loss: 0.0303\n",
            "Epoch 20/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9377 - loss: 0.0226 - val_accuracy: 0.9043 - val_loss: 0.0302\n",
            "Epoch 21/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9381 - loss: 0.0225 - val_accuracy: 0.9046 - val_loss: 0.0302\n",
            "Epoch 22/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9401 - loss: 0.0222 - val_accuracy: 0.9036 - val_loss: 0.0303\n",
            "Epoch 23/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9404 - loss: 0.0217 - val_accuracy: 0.9029 - val_loss: 0.0302\n",
            "Epoch 24/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9396 - loss: 0.0218 - val_accuracy: 0.9027 - val_loss: 0.0303\n",
            "Epoch 25/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9417 - loss: 0.0215 - val_accuracy: 0.9024 - val_loss: 0.0309\n",
            "Epoch 26/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9398 - loss: 0.0214 - val_accuracy: 0.9064 - val_loss: 0.0302\n",
            "Epoch 27/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9436 - loss: 0.0211 - val_accuracy: 0.9065 - val_loss: 0.0300\n",
            "Epoch 28/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9454 - loss: 0.0207 - val_accuracy: 0.9039 - val_loss: 0.0309\n",
            "Training model 3/5 (seed=30)\n",
            "Epoch 1/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5822 - loss: 0.0962 - val_accuracy: 0.8082 - val_loss: 0.0639\n",
            "Epoch 2/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7937 - loss: 0.0620 - val_accuracy: 0.8629 - val_loss: 0.0460\n",
            "Epoch 3/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8512 - loss: 0.0471 - val_accuracy: 0.8793 - val_loss: 0.0392\n",
            "Epoch 4/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8769 - loss: 0.0399 - val_accuracy: 0.8876 - val_loss: 0.0363\n",
            "Epoch 5/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8907 - loss: 0.0359 - val_accuracy: 0.8945 - val_loss: 0.0337\n",
            "Epoch 6/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9006 - loss: 0.0330 - val_accuracy: 0.8954 - val_loss: 0.0327\n",
            "Epoch 7/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9081 - loss: 0.0308 - val_accuracy: 0.8988 - val_loss: 0.0319\n",
            "Epoch 8/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9127 - loss: 0.0295 - val_accuracy: 0.9033 - val_loss: 0.0309\n",
            "Epoch 9/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9172 - loss: 0.0282 - val_accuracy: 0.9013 - val_loss: 0.0309\n",
            "Epoch 10/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9197 - loss: 0.0275 - val_accuracy: 0.9017 - val_loss: 0.0306\n",
            "Epoch 11/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9232 - loss: 0.0263 - val_accuracy: 0.9028 - val_loss: 0.0303\n",
            "Epoch 12/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9250 - loss: 0.0259 - val_accuracy: 0.9023 - val_loss: 0.0303\n",
            "Epoch 13/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9295 - loss: 0.0248 - val_accuracy: 0.9024 - val_loss: 0.0305\n",
            "Epoch 14/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9277 - loss: 0.0247 - val_accuracy: 0.9018 - val_loss: 0.0303\n",
            "Epoch 15/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9301 - loss: 0.0244 - val_accuracy: 0.9041 - val_loss: 0.0303\n",
            "Epoch 16/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9324 - loss: 0.0238 - val_accuracy: 0.9034 - val_loss: 0.0301\n",
            "Epoch 17/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9338 - loss: 0.0234 - val_accuracy: 0.9045 - val_loss: 0.0301\n",
            "Epoch 18/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9340 - loss: 0.0231 - val_accuracy: 0.9030 - val_loss: 0.0301\n",
            "Epoch 19/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9371 - loss: 0.0228 - val_accuracy: 0.9050 - val_loss: 0.0303\n",
            "Epoch 20/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9371 - loss: 0.0227 - val_accuracy: 0.9053 - val_loss: 0.0300\n",
            "Epoch 21/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.0220 - val_accuracy: 0.9054 - val_loss: 0.0300\n",
            "Epoch 22/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9378 - loss: 0.0222 - val_accuracy: 0.9053 - val_loss: 0.0298\n",
            "Epoch 23/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9404 - loss: 0.0218 - val_accuracy: 0.9048 - val_loss: 0.0299\n",
            "Epoch 24/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9403 - loss: 0.0217 - val_accuracy: 0.9050 - val_loss: 0.0301\n",
            "Epoch 25/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9439 - loss: 0.0208 - val_accuracy: 0.9051 - val_loss: 0.0302\n",
            "Epoch 26/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9421 - loss: 0.0210 - val_accuracy: 0.9032 - val_loss: 0.0305\n",
            "Epoch 27/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9414 - loss: 0.0212 - val_accuracy: 0.9031 - val_loss: 0.0306\n",
            "Epoch 28/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9449 - loss: 0.0205 - val_accuracy: 0.9031 - val_loss: 0.0309\n",
            "Epoch 29/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9431 - loss: 0.0209 - val_accuracy: 0.9040 - val_loss: 0.0306\n",
            "Epoch 30/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9436 - loss: 0.0208 - val_accuracy: 0.9056 - val_loss: 0.0305\n",
            "Epoch 31/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9467 - loss: 0.0202 - val_accuracy: 0.9043 - val_loss: 0.0304\n",
            "Epoch 32/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9455 - loss: 0.0204 - val_accuracy: 0.8996 - val_loss: 0.0315\n",
            "Training model 4/5 (seed=40)\n",
            "Epoch 1/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5814 - loss: 0.0946 - val_accuracy: 0.8121 - val_loss: 0.0635\n",
            "Epoch 2/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7996 - loss: 0.0612 - val_accuracy: 0.8611 - val_loss: 0.0461\n",
            "Epoch 3/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8518 - loss: 0.0471 - val_accuracy: 0.8834 - val_loss: 0.0392\n",
            "Epoch 4/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8770 - loss: 0.0403 - val_accuracy: 0.8923 - val_loss: 0.0356\n",
            "Epoch 5/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8894 - loss: 0.0364 - val_accuracy: 0.8956 - val_loss: 0.0337\n",
            "Epoch 6/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8990 - loss: 0.0337 - val_accuracy: 0.8996 - val_loss: 0.0324\n",
            "Epoch 7/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9065 - loss: 0.0315 - val_accuracy: 0.8984 - val_loss: 0.0320\n",
            "Epoch 8/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9090 - loss: 0.0301 - val_accuracy: 0.9002 - val_loss: 0.0314\n",
            "Epoch 9/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.0286 - val_accuracy: 0.9012 - val_loss: 0.0309\n",
            "Epoch 10/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9176 - loss: 0.0277 - val_accuracy: 0.9018 - val_loss: 0.0306\n",
            "Epoch 11/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9211 - loss: 0.0269 - val_accuracy: 0.9022 - val_loss: 0.0304\n",
            "Epoch 12/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9229 - loss: 0.0262 - val_accuracy: 0.9013 - val_loss: 0.0307\n",
            "Epoch 13/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9251 - loss: 0.0257 - val_accuracy: 0.9016 - val_loss: 0.0301\n",
            "Epoch 14/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 0.0248 - val_accuracy: 0.9020 - val_loss: 0.0304\n",
            "Epoch 15/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9298 - loss: 0.0246 - val_accuracy: 0.9028 - val_loss: 0.0305\n",
            "Epoch 16/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9309 - loss: 0.0241 - val_accuracy: 0.9037 - val_loss: 0.0302\n",
            "Epoch 17/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9320 - loss: 0.0238 - val_accuracy: 0.9029 - val_loss: 0.0301\n",
            "Epoch 18/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9343 - loss: 0.0232 - val_accuracy: 0.9045 - val_loss: 0.0300\n",
            "Epoch 19/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9360 - loss: 0.0230 - val_accuracy: 0.9032 - val_loss: 0.0302\n",
            "Epoch 20/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9377 - loss: 0.0224 - val_accuracy: 0.9028 - val_loss: 0.0306\n",
            "Epoch 21/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9391 - loss: 0.0220 - val_accuracy: 0.9034 - val_loss: 0.0306\n",
            "Epoch 22/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.0220 - val_accuracy: 0.8997 - val_loss: 0.0311\n",
            "Epoch 23/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9382 - loss: 0.0222 - val_accuracy: 0.9034 - val_loss: 0.0305\n",
            "Epoch 24/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9427 - loss: 0.0212 - val_accuracy: 0.9037 - val_loss: 0.0313\n",
            "Epoch 25/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9412 - loss: 0.0217 - val_accuracy: 0.9021 - val_loss: 0.0310\n",
            "Epoch 26/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9420 - loss: 0.0211 - val_accuracy: 0.9049 - val_loss: 0.0307\n",
            "Epoch 27/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.0212 - val_accuracy: 0.9034 - val_loss: 0.0308\n",
            "Epoch 28/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9435 - loss: 0.0206 - val_accuracy: 0.9007 - val_loss: 0.0305\n",
            "Training model 5/5 (seed=50)\n",
            "Epoch 1/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5850 - loss: 0.0943 - val_accuracy: 0.8161 - val_loss: 0.0628\n",
            "Epoch 2/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.0601 - val_accuracy: 0.8620 - val_loss: 0.0457\n",
            "Epoch 3/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8520 - loss: 0.0468 - val_accuracy: 0.8821 - val_loss: 0.0391\n",
            "Epoch 4/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8753 - loss: 0.0403 - val_accuracy: 0.8895 - val_loss: 0.0358\n",
            "Epoch 5/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8896 - loss: 0.0361 - val_accuracy: 0.8969 - val_loss: 0.0337\n",
            "Epoch 6/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8978 - loss: 0.0337 - val_accuracy: 0.8967 - val_loss: 0.0328\n",
            "Epoch 7/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9059 - loss: 0.0314 - val_accuracy: 0.8989 - val_loss: 0.0319\n",
            "Epoch 8/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9110 - loss: 0.0300 - val_accuracy: 0.9016 - val_loss: 0.0316\n",
            "Epoch 9/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9147 - loss: 0.0287 - val_accuracy: 0.9003 - val_loss: 0.0311\n",
            "Epoch 10/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9196 - loss: 0.0277 - val_accuracy: 0.9008 - val_loss: 0.0310\n",
            "Epoch 11/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9222 - loss: 0.0267 - val_accuracy: 0.9025 - val_loss: 0.0302\n",
            "Epoch 12/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9233 - loss: 0.0262 - val_accuracy: 0.9028 - val_loss: 0.0305\n",
            "Epoch 13/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9263 - loss: 0.0256 - val_accuracy: 0.9033 - val_loss: 0.0307\n",
            "Epoch 14/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9270 - loss: 0.0253 - val_accuracy: 0.9040 - val_loss: 0.0302\n",
            "Epoch 15/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9315 - loss: 0.0242 - val_accuracy: 0.9025 - val_loss: 0.0304\n",
            "Epoch 16/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9342 - loss: 0.0237 - val_accuracy: 0.9032 - val_loss: 0.0303\n",
            "Epoch 17/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9316 - loss: 0.0239 - val_accuracy: 0.9028 - val_loss: 0.0310\n",
            "Epoch 18/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9347 - loss: 0.0232 - val_accuracy: 0.9032 - val_loss: 0.0310\n",
            "Epoch 19/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9346 - loss: 0.0232 - val_accuracy: 0.9035 - val_loss: 0.0306\n",
            "Epoch 20/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9370 - loss: 0.0224 - val_accuracy: 0.9059 - val_loss: 0.0302\n",
            "Epoch 21/200\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9380 - loss: 0.0224 - val_accuracy: 0.9026 - val_loss: 0.0311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ensemble_predict(models, X):\n",
        "    probs = np.array([\n",
        "        model.predict(X).ravel()\n",
        "        for model in models\n",
        "    ])\n",
        "    return probs.mean(axis=0)\n"
      ],
      "metadata": {
        "id": "P_Zf4vx1487n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "val_probs = ensemble_predict(models, X_val_scaled)\n",
        "\n",
        "thresholds = np.linspace(0.2, 0.8, 301)\n",
        "best_t, best_acc = 0.5, 0.0\n",
        "\n",
        "for t in thresholds:\n",
        "    acc = accuracy_score(y_val, (val_probs >= t).astype(int))\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_t = t\n",
        "\n",
        "print(f\"Optimal threshold (val): {best_t:.3f}\")\n",
        "print(f\"Validation accuracy: {best_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0soMM9NI5A4h",
        "outputId": "c5b003e9-8405-48df-a409-3de259fd31b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Optimal threshold (val): 0.462\n",
            "Validation accuracy: 0.9242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_probs = ensemble_predict(models, X_test_scaled)\n",
        "test_preds = (test_probs >= best_t).astype(int)\n",
        "\n",
        "test_acc = accuracy_score(y_test, test_preds)\n",
        "test_auc = roc_auc_score(y_test, test_probs)\n",
        "\n",
        "print(f\"Ensemble Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Ensemble Test ROC-AUC:  {test_auc:.4f}\")\n",
        "\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    test_preds,\n",
        "    target_names=[\"SEP\", \"ENT\"]\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dUbF4Zs5Fgc",
        "outputId": "4732c5f1-759a-4f59-f026-41c583865602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Ensemble Test Accuracy: 0.9221\n",
            "Ensemble Test ROC-AUC:  0.9835\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         SEP       0.92      0.93      0.92     10000\n",
            "         ENT       0.93      0.92      0.92     10000\n",
            "\n",
            "    accuracy                           0.92     20000\n",
            "   macro avg       0.92      0.92      0.92     20000\n",
            "weighted avg       0.92      0.92      0.92     20000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indiv_probs = np.array([\n",
        "    model.predict(X_test_scaled).ravel()\n",
        "    for model in models\n",
        "])\n",
        "\n",
        "print(\"Mean disagreement:\",\n",
        "      np.mean(np.std(indiv_probs, axis=0)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plC0as3S7Ggp",
        "outputId": "7ca732ef-9312-45e7-bc2e-c18ea2a1aac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Mean disagreement: 0.045317367\n"
          ]
        }
      ]
    }
  ]
}